\section{Fisher-Kernel}
\label{sec:fisher}

In 2006 Florent Perronnin and Christopher Dance proposed to use Fisher kernel for image categorization \cite{Perronnin2006}. They describe Fisher kernels as a method to combine the benefits of generative and discriminative approaches (shown by \cite{jaakkola1999exploiting}). To apply Fisher kernels on visual vocabularies, they denote

\begin{equation}
\mathcal{L} (X|\lambda) = \log p(X|\lambda)
\end{equation}

With $X = \{x_t, t = 1 \dots T\}$ as a set of low-level feature vectors and $\lambda = \{w_i, \mu_i, \Sigma_i, i = 1 \dots N\}$ as a set of parameters of a \acf{GMM} ($w, \mu, \Sigma$ denote the weight, mean and covariance matrix). This corresponds to (under an independence assumption)

\begin{equation}
\mathcal{L} (X|\lambda) = \sum_{t=1}^{T} \log p(x_t|\lambda)
\end{equation}

This results in the likelihood (\eqnref{fisher_likelihood}) that a observation $x_t$ was generated by the \ac{GMM}.

\begin{equation}
p(x_t|\lambda) = \sum_{i=1}^{N} w_i p_i (x_t|\lambda)
\label{eqn:fisher_likelihood}
\end{equation}

where the weights are constrained by \ref{eqn:fisher_weights}.

\begin{equation}
\sum_{i=1}^{N} w_i = 1
\label{eqn:fisher_weights}
\end{equation}

The authors defined the components $p_i$ as

\begin{equation}
p_i(x|\lambda) = \frac{
	\ 	exp \{-\frac{1}{2} (x-\mu_i)' \Sigma_{i}^{-1} (x-\mu_i)\}
}{
	(2 \pi)^{D/2} | \Sigma_i |^{1/2}
}
\end{equation}

with $D$ as feature vector dimensionality and $|.|$ as determinant operator.
% TODO