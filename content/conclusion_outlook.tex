\chapter{Conclusion}

The experimental results showed that the total query time can be reduced to a reasonable low amount, even if the queried database actually represents codebooks at every pixel with several hundred entries. Nevertheless, one of the bases of the algorithm (the codebooks) does not seem to provide the desired performances. One of the reasons may be the loss of the information about the exact locations and the sizes of the input feature patches. Another reason could be that the reduction of the 775 dimensional features to a codebook shadows the essential information which actually represents the class of the query image. As the current used system is unsupervised at the database creation, no information is available for the feature extraction nor which feature patch sizes should be included into a codebook. Furthermore, some of the experimental results indicate that smaller image parts with lesser feature patches getting lost. This is based on the fact that a higher amount of features which add up would produce a higher profile codebook compared to a lower amount of features. Approaches like ExemplarSVM which operate directly on the feature descriptors have to define the similarity between the descriptors themselves, whilst the presented approach has a higher dependency on the sorting of the describtors into the codebook bins. This means a sort of similarity assignments is required to preserve the performance of approaches which does not use this additional layer.

The presented approach contained some promising parts (for example the ability to precompute a whole image database and extract arbitrary codebooks at query time), but can't compete against algorithms like ExemplarSVM. Nevertheless, additional optimizations in terms of program code structure could reduce the query time even further, and therefore could be used as a filter algorithm to reduce the effort for more accurate algorithms.

\chapter{Outlook}