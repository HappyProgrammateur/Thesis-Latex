Automatically generated by Mendeley Desktop 1.14
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Chih-WeiHsuChih-ChungChang2008a,
abstract = {The support vector machine (SVM) is a popular classi cation technique. However, beginners who are not familiar with SVM often get unsatisfactory results since they miss some easy but signi cant steps. In this guide, we propose a simple procedure which usually gives reasonable results. developed well-differentiated superficial transitional cell bladder cancer. CONCLUSIONS: Patients with SCI often prefer SPC than other methods offered to them, because of quality-of-life issues. The incidence of significant complications might not be as high as previously reported, and with a commitment to careful follow-up, SPC can be a safe option for carefully selected patients if adequate surveillance can be ensured.},
author = {Hsu, Chih-Wei and Chang, Chih-Chung and Lin, Chih-Jen},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/guide.pdf:pdf},
journal = {BJU international},
number = {1},
pages = {1396--400},
title = {{A Practical Guide to Support Vector Classification}},
url = {http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf},
volume = {101},
year = {2008}
}
@inproceedings{7045987,
author = {Pourian, N and Manjunath, B S},
booktitle = {Applications of Computer Vision (WACV), 2015 IEEE Winter Conference on},
doi = {10.1109/WACV.2015.133},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/07045987.pdf:pdf},
keywords = {Communities,Databases,Image color analysis,Image edge detection,Image segmentation,Training,Visualization,community detection method,database,image matching,image patches,image representation,image retrieval,image segmentation,location configuration,object detection,object representations,size configuration,spatial configuration,subgraph matching method},
month = jan,
pages = {960--967},
title = {{Retrieval of Images with Objects of Specific Size, Location, and Spatial Configuration}},
year = {2015}
}
@article{Moosmann2007a,
abstract = {Some of the most effective recent methods for content-based image classification work by extracting dense or sparse local image descriptors, quantizing them according to a coding rule such as k-means vector quantization, accumulating histograms of the resulting “visual word ” codes over the image, and classifying these with a conventional classifier such as an SVM. Large numbers of descriptors and large codebooks are needed for good results and this becomes slow using k-means. We introduce Extremely Randomized Clustering Forests – ensembles of randomly created clustering trees – and show that these provide more accurate results, much faster training and testing and good resistance to background clutter in several state-of-the-art image classification tasks.},
author = {Moosmann, Frank and Triggs, Bill and Jurie, Frederic},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/MTJ-nips06.pdf:pdf},
isbn = {9780262195683},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems 19},
pages = {985--992},
title = {{Fast Discriminative Visual Codebooks using Randomized Clustering Forests}},
year = {2007}
}
@inproceedings{6836075,
author = {Takami, M and Bell, P and Ommer, B},
booktitle = {Applications of Computer Vision (WACV), 2014 IEEE Winter Conference on},
doi = {10.1109/WACV.2014.6836075},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/06836075.pdf:pdf},
keywords = {Art,Feature extraction,Image databases,Search problems,Support vector machines,Training,Visualization,digitization campaigns,duplicate detection,exemplar SVM based classifier,image classification,image databases,image retrieval,learning (artificial intelligence),object detection,offline learning,query regions,search method,support vector machines},
month = mar,
pages = {377--384},
title = {{Offline learning of prototypical negatives for efficient online Exemplar SVM}},
year = {2014}
}
@article{Heidemann2005,
abstract = {Large image collections require efficient organization and visualization. This paper describes an approach to establish image categories automatically by unsupervised learning. The method works free of context and previous knowledge: in a first stage, features are formed automatically, then images are clustered to form categories. The human database designer has to decide only whether a category is useful or too inhomogeneous from a high level point of view. To collect images that cannot be categorized automatically, an additional 'miscellaneous' category exists. Categories are visualized by displaying the most typical image(s) of the categories as thumbnails. The main benefit of the approach is that it deals with color and shape in a unified way on a local scale, combined with the advantages of histogram techniques on the global scale. To judge results, an evaluation scheme which is adequate for the task of categorization is proposed. © 2005 Elsevier B.V. All rights reserved.},
author = {Heidemann, Gunther},
doi = {10.1016/j.imavis.2005.05.016},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/1-s2.0-S0262885605000661-main.pdf:pdf},
isbn = {0262-8856},
issn = {02628856},
journal = {Image and Vision Computing},
keywords = {Color features,Image categorization,Image indexing,Image retrieval,Interest points,Object recognition,Salient points,Unsupervised learning,Vector quantization},
number = {10},
pages = {861--876},
title = {{Unsupervised image categorization}},
volume = {23},
year = {2005}
}
@inproceedings{4587586,
author = {Lampert, Christoph H. and Blaschko, Matthew B. and Hofmann, Thomas},
booktitle = {Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on},
doi = {10.1109/CVPR.2008.4587586},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/04587586.pdf:pdf},
issn = {1063-6919},
keywords = {Computational efficiency,Cybernetics,ESS method,Electronic switching systems,Image recognition,Kernel,Nearest neighbor searches,Object detection,Object recognition,Performance evaluation,Pixel,branch-and-bound scheme,efficient subwindow search,image classification,image retrieval,object detection,object localization,object recognition systems,object retrieval,sliding windows,subimage classifier functions,tree searching},
month = jun,
pages = {1--8},
title = {{Beyond sliding windows: Object localization by efficient subwindow search}},
year = {2008}
}
@article{Lowe2004,
abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
address = {Hingham, MA, USA},
author = {Lowe, David G},
doi = {10.1023/B:VISI.0000029664.99615.94},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/ijcv04.pdf:pdf},
issn = {0920-5691},
journal = {Int. J. Comput. Vision},
keywords = {image matching,invariant features,object recognition,scale invariance},
month = nov,
number = {2},
pages = {91--110},
publisher = {Kluwer Academic Publishers},
title = {{Distinctive Image Features from Scale-Invariant Keypoints}},
url = {http://dx.doi.org/10.1023/B:VISI.0000029664.99615.94},
volume = {60},
year = {2004}
}
@article{Gong1994,
abstract = {While general object recognition is difficult, it is relatively easy to capture some primitive image properties such as color distribution, prominent regions and their geometrical properties from an image and use these features to narrow down the search space when attempts to retrieving images by contents from an image database are made. The authors are building an image database in which images are indexed by both the numerical index keys generated automatically from the captured primitive image features using a set of rules, and traditional descriptive keywords entered by users when images are loaded. Users can either use the descriptive keywords or provide information regarding these image properties to query and retrieve images from the database. With this approach, the authors turn the difficult problem of image matching into image retrieval by index keys, which can be performed easily and rapidly using current database techniques. Initial experiments on the image database system show promising performance},
author = {Gong, Yihong and Zhang, Hongjiang and Chuan, H.C. and Sakauchi, M.},
doi = {10.1109/MMCS.1994.292444},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/00292444.pdf:pdf},
isbn = {0-8186-5530-5},
journal = {Multimedia Computing and Systems, 1994., Proceedings of the International Conference on},
keywords = {a re-,and no visual,associated with the images,data are employed,image,image even though the,not associated with that,properties of the underlying,the query uses keywords,trieval will fail if,which were},
title = {{An image database system with content capturing and fast image indexing abilities}},
year = {1994}
}
@article{Shi:2000:NCI:351581.351611,
address = {Washington, DC, USA},
author = {Shi, Jianbo and Malik, Jitendra},
doi = {10.1109/34.868688},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/SM-ncut.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
keywords = {Grouping,graph partitioning.,image segmentation},
month = aug,
number = {8},
pages = {888--905},
publisher = {IEEE Computer Society},
title = {{Normalized Cuts and Image Segmentation}},
url = {http://dx.doi.org/10.1109/34.868688},
volume = {22},
year = {2000}
}
@article{Faloutsos1994,
abstract = {In the QBIC (Query By Image Content) project we are studying methods to query large on-line image databases using the images' content as the basis of the queries. Examples of the content we use include color, texture, shape, position, and dominant edges of image objects and regions. Potential applications include medical (“Give me other images that contain a tumor with a texture like this one”), photo-journalism (“Give me images that have blue at the top and red at the bottom”), and many others in art, fashion, cataloging, retailing, and industry. We describe a set of novel features and similarity measures allowing query by image content, together with the QBIC system we implemented. We demonstrate the effectiveness of our system with normalized precision and recall experiments on test databases containing over 1000 images and 1000 objects populated from commercially available photo clip art images, and of images of airplane silhouettes. We also present new methods for efficient processing of QBIC queries that consist of filtering and indexing steps. We specifically address two problems: (a) non Euclidean distance measures; and (b) the high dimensionality of feature vectors. For the first problem, we introduce a new theorem that makes efficient filtering possible by bounding the non-Euclidean, full cross-term quadratic distance expression with a simple Euclidean distance. For the second, we illustrate how orthogonal transforms, such as Karhunen Loeve, can help reduce the dimensionality of the search space. Our methods are general and allow some “false hits” but no false dismissals. The resulting QBIC system offers effective retrieval using image content, and for large image databases significant speedup over straightforward indexing alternatives. The system is implemented in X/Motif and C running on an RS/6000.},
author = {Faloutsos, C. and Barber, R. and Flickner, M. and Hafner, J. and Niblack, W. and Petkovic, D. and Equitz, W.},
doi = {10.1007/BF00962238},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/QBIC.pdf:pdf},
issn = {09259902},
journal = {Journal of Intelligent Information Systems},
keywords = {content-based retrieval,image database,image indexing,similarity retrieval},
number = {3-4},
pages = {231--262},
title = {{Efficient and effective Querying by Image Content}},
volume = {3},
year = {1994}
}
@article{Wang2014,
abstract = {Learning fine-grained image similarity is a challenging task. It needs to capture between-class and within-class image differences. This paper proposes a deep ranking model that employs deep learning techniques to learn similarity metric directly from images.It has higher learning capability than models based on hand-crafted features. A novel multiscale network structure has been developed to describe the images effectively. An efficient triplet sampling algorithm is proposed to learn the model with distributed asynchronized stochastic gradient. Extensive experiments show that the proposed algorithm outperforms models based on hand-crafted visual features and deep classification models.},
archivePrefix = {arXiv},
arxivId = {arXiv:1404.4661v1},
author = {Wang, Jiang and Song, Yang and Leung, Thomas and Rosenberg, Chuck and Wang, Jingbin and Philbin, James and Chen, Bo and Wu, Ying},
doi = {10.1109/CVPR.2014.180},
eprint = {arXiv:1404.4661v1},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/deep\_ranking.pdf:pdf},
isbn = {9781479951178},
issn = {10636919},
journal = {Cvpr},
pages = {1386--1393},
title = {{Learning Fine-grained Image Similarity with Deep Ranking}},
year = {2014}
}
@inproceedings{Hariharan2012,
abstract = {Object detection has over the past few years converged on using linear SVMs over HOG features. Training linear SVMs however is quite expensive, and can become intractable as the number of categories increase. In this work we revisit a much older technique, viz. Linear Discriminant Analysis, and show that LDA models can be trained almost trivially, and with little or no loss in performance. The covariance matrices we estimate capture properties of natural images. Whitening HOG features with these covariances thus removes naturally occuring correlations between the HOG features. We show that these whitened features (which we call WHO) are considerably better than the original HOG features for computing similarities, and prove their usefulness in clustering. Finally, we use our findings to produce an object detection system that is competitive on PASCAL VOC 2007 while being considerably easier to train and test.},
author = {Hariharan, Bharath and Malik, Jitendra and Ramanan, Deva},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-33765-9\_33},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/who.pdf:pdf},
isbn = {9783642337642},
issn = {03029743},
number = {PART 4},
pages = {459--472},
title = {{Discriminative decorrelation for clustering and classification}},
volume = {7575 LNCS},
year = {2012}
}
@article{Baraldi1995,
abstract = {Presents an implementation of an artificial neural network (ANN)$\backslash$nwhich performs unsupervised detection of recognition categories from$\backslash$narbitrary sequences of multivalued input patterns. The proposed ANN is$\backslash$ncalled Simplified Adaptive Resonance Theory Neural Network (SARTNN).$\backslash$nFirst, an Improved Adaptive Resonance Theory 1 (IART1)-based neural$\backslash$nnetwork for binary pattern analysis is discussed and a Simplified ART1$\backslash$n(SART1) model is proposed. Second, the SART1 model is extended to$\backslash$nmultivalued input pattern clustering and SARTNN is presented. A$\backslash$nnormalized coefficient which measures the degree of match between two$\backslash$nmultivalued vectors, the Vector Degree of Match (VDM), provides SARTNN$\backslash$nwith the metric needed to perform clustering. Every ART architecture$\backslash$nguarantees both plasticity and stability to the unsupervised learning$\backslash$nstage. The SARTNN plasticity requirement is satisfied by implementing$\backslash$nits attentional subsystem as a self-organized, feed-forward, flat$\backslash$nKohonen's ANN (KANN). The SARTNN stability requirement is properly$\backslash$ndriven by its orienting subsystem. SARTNN processes multivalued input$\backslash$nvectors while featuring a simplified architectural acid mathematical$\backslash$nmodel with respect to both the ART1 and the ART2 models, the latter$\backslash$nbeing the ART model fitted to multivalued input pattern categorization.$\backslash$nWhile the ART2 model exploits ten user-defined parameters, SARTNN$\backslash$nrequires only two user-defined parameters to be run: the first parameter$\backslash$nis the vigilance threshold, \&amp;rho;, that affects the network's$\backslash$nsensibility in detecting new output categories, whereas the second$\backslash$nparameter, \&amp;tau;, is related to the network's learning rate. Both$\backslash$nparameters have an intuitive physical meaning and allow the user to$\backslash$nchoose easily the proper discriminating power of the category extraction$\backslash$nalgorithm. The SARTNN performance is tested as a satellite image$\backslash$nclustering algorithm. A chromatic component extractor is recommended in$\backslash$na satellite image preprocessing stage, in order to pursue SARTNN$\backslash$ninvariant pattern recognition. In comparison with classical clustering$\backslash$nalgorithms like ISODATA, the implemented system gives good results in$\backslash$nterms of ease of use, parameter robustness and computation time. SARTNN$\backslash$nshould improve the performance of a Constraint Satisfaction Neural$\backslash$nNetwork (CSNN) for image segmentation. SARTNN, exploited as a$\backslash$nself-organizing first layer, should also improve the performance of both$\backslash$nthe CounterPropagation Neural Network (CPNN) and the Reduced$\backslash$nconnectivity Coulomb Energy Neural Network (RCENN)},
author = {Baraldi, a. and Parmiggiani, F.},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/00377930.pdf:pdf},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
number = {2},
title = {{A neural network for unsupervised categorization of multivalued$\backslash$ninput patterns: an application to satellite image clustering}},
volume = {33},
year = {1995}
}
@article{Dalal2005,
abstract = {We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.},
archivePrefix = {arXiv},
arxivId = {chao-dyn/9411012},
author = {Dalal, Navneet and Triggs, Bill},
doi = {10.1109/CVPR.2005.177},
eprint = {9411012},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/hog\_cvpr2005.pdf:pdf},
isbn = {0769523722},
issn = {1063-6919},
journal = {Proceedings - 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, CVPR 2005},
pages = {886--893},
pmid = {9230594},
primaryClass = {chao-dyn},
title = {{Histograms of oriented gradients for human detection}},
volume = {I},
year = {2005}
}
@article{Perronnin2010,
abstract = {The Fisher kernel (FK) is a generic framework which combines the benefits of generative and discriminative approaches. In the context of image classification the FK was shown to extend the popular bag-of-visual-words (BOV) by going beyond count statistics. However, in practice, this enriched representation has not yet shown its superiority over the BOV. In the first part we show that with several well-motivated modifications over the original framework we can boost the accuracy of the FK. On PASCAL VOC 2007 we increase the Average Precision (AP) from 47.9\% to 58.3\%. Similarly, we demonstrate state-of-the-art accuracy on CalTech 256. A major advantage is that these results are obtained using only SIFT descriptors and costless linear classifiers. Equipped with this representation, we can now explore image classification on a larger scale. In the second part, as an application, we compare two abundant resources of labeled images to learn classifiers: ImageNet and Flickr groups. In an evaluation involving hundreds of thousands of training images we show that classifiers learned on Flickr groups perform surprisingly well (although they were not intended for this purpose) and that they can complement classifiers learned on more carefully annotated datasets.},
author = {Perronnin, Florent and S\'{a}nchez, Jorge and Mensink, Thomas},
doi = {10.1007/978-3-642-15561-1\_11},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/peronnin\_etal\_ECCV10.pdf:pdf},
isbn = {364215560X},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {PART 4},
pages = {143--156},
title = {{Improving the Fisher kernel for large-scale image classification}},
volume = {6314 LNCS},
year = {2010}
}
@inproceedings{Arthur:2007:KAC:1283383.1283494,
address = {Philadelphia, PA, USA},
author = {Arthur, David and Vassilvitskii, Sergei},
booktitle = {Proceedings of the Eighteenth Annual ACM-SIAM Symposium on Discrete Algorithms},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/kmeans++.pdf:pdf},
isbn = {978-0-898716-24-5},
pages = {1027--1035},
publisher = {Society for Industrial and Applied Mathematics},
series = {SODA '07},
title = {{K-means++: The Advantages of Careful Seeding}},
url = {http://dl.acm.org/citation.cfm?id=1283383.1283494},
year = {2007}
}
@article{Malisiewicz2011,
abstract = {This paper proposes a conceptually simple but surprisingly powerful method which combines the effectiveness of a discriminative object detector with the explicit correspondence offered by a nearest-neighbor approach. The method is based on training a separate linear SVM classifier for every exemplar in the training set. Each of these Exemplar-SVMs is thus defined by a single positive instance and millions of negatives. While each detector is quite specific to its exemplar, we empirically observe that an ensemble of such Exemplar-SVMs offers surprisingly good generalization. Our performance on the PASCAL VOC detection task is on par with the much more complex latent part-based model of Felzenszwalb et al., at only a modest computational cost increase. But the central benefit of our approach is that it creates an explicit association between each detection and a single training exemplar. Because most detections show good alignment to their associated exemplar, it is possible to transfer any available exemplar meta-data (segmentation, geometric structure, 3D model, etc.) directly onto the detections, which can then be used as part of overall scene understanding.},
author = {Malisiewicz, Tomasz and Gupta, Abhinav and Efros, Alexei A.},
doi = {10.1109/ICCV.2011.6126229},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/exemplarsvm-iccv11.pdf:pdf;:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/exemplarsvm-mit-talk.pdf:pdf},
isbn = {9781457711015},
issn = {1550-5499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {89--96},
title = {{Ensemble of exemplar-SVMs for object detection and beyond}},
year = {2011}
}
@article{7054551,
author = {Zheng, Liang and Wang, Shengjin and Liu, Ziqiong and Tian, Qi},
doi = {10.1109/TMM.2015.2408563},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/07054551.pdf:pdf},
issn = {1520-9210},
journal = {Multimedia, IEEE Transactions on},
keywords = {Accuracy,Early termination,Feature extraction,Image retrieval,Indexes,Q-Index,Quantization (signal),TF-IDF,Visualization,competitive retrieval accuracy,early termination,fast image retrieval,image retrieval,impact score,integer,inverted index organization,local features impact score,memory consumption,online retrieval process,query pruning},
month = may,
number = {5},
pages = {648--659},
title = {{Fast Image Retrieval: Query Pruning and Early Termination}},
volume = {17},
year = {2015}
}
@article{Chen1997,
abstract = {We exploit the techniques of tree structured vector quantization
(TSVQ), branch and bound search, and the triangle inequality to speed
the search of large image databases. Our method can reduce search
computation required to locate images which best match a query image
provided by a user. While exact search is possible, a free parameter
allows search accuracy to be reduced, thereby providing a substantially
better speed-up versus accuracy tradeoff},
author = {Chen, Jau-Yen Chen Jau-Yen and Bouman, C.a. and Allebach, J.P.},
doi = {10.1109/ICIP.1997.638624},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/00638624.pdf:pdf},
isbn = {0-8186-8183-7},
journal = {Proceedings of International Conference on Image Processing},
pages = {827--830},
title = {{Fast image database search using tree-structured VQ}},
volume = {2},
year = {1997}
}
@article{Perronnin2006,
author = {Perronnin, Florent and Dance, Christopher},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/PerronninDance\_CVPR2007 - Fisher Kernels on Visual Vocabularies for Image categorization.pdf:pdf},
journal = {Proc. \{CVPR\}},
title = {{Fisher Kernels on Visual Vocabularies for Image Categorizaton}},
year = {2006}
}
@misc{Pascal2011,
title = {{Visual Object Classes Challenge 2011}},
url = {http://host.robots.ox.ac.uk/pascal/VOC/voc2011/index.html},
urldate = {2015-09-30},
year = {2011}
}
@article{Moosmann2008,
abstract = {Some of the most effective recent methods for content-based image classification work by quantizing image descriptors, and accumulating histograms of the resulting visual word codes. Large numbers of descriptors and large codebooks are required for good results and this becomes slow using k-means. We introduce Extremely Randomized Clustering Forests ensembles of randomly created clustering trees and show that they provide more accurate results, much faster training and testing, and good resistance to background clutter. Second, an efficient image classification method is proposed. It combines ERC-Forests and saliency maps very closely with the extraction of image information. For a given image, a classifier builds a saliency map online and uses it to classify the image. We show in several state-of-the-art image classification tasks that this method can speed up the classification process enormously. Finally, we show that the proposed ERC-Forests can also be used very successfully for learning distance between images. The distance computation algorithm consists of learning the characteristic differences between local descriptors sampled from pairs of same or different objects. These differences are vector quantized by ERC-Forests and the similarity measure is computed from this quantization. The similarity measure has been evaluated on four very different datasets and always outperforms the state-of-the-art competitive approaches.},
author = {Moosmann, Frank and Nowak, Eric and Jurie, Frederic},
doi = {10.1109/TPAMI.2007.70822},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/moosman-nowak-jurie-pami08.pdf:pdf},
isbn = {01628828 (ISSN)},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Image classification,Object recognition,Randomized trees,Similarity measure},
number = {9},
pages = {1632--1646},
pmid = {18617720},
title = {{Randomized clustering forests for image classification}},
volume = {30},
year = {2008}
}
@article{Giveki2015,
abstract = {Searching interested images based on visual properties of images is a challenging problem and it has received considerable attention from researchers in the fields like image processing, computer vision and multimedia systems in the last 20 years. While the importance and the effect of the image features like color, texture and shape have been taken into account in many papers, there have not been many studies on the importance of the color spaces on the performance of Content Based Image Retrieval (CBIR) systems. In this paper we first experimentally study the effect of choosing color space on the performance of content based image retrieval using Wavelet decomposition of each color channel. To this end, the retrieval results of different color spaces like RGB, YUV, HSV, YCbCr and Lab are analyzed. Then as a result a new Content Based Retrieval model using Wavelet Transform in Lab color space and Color Moments is proposed. In order to increase the efficiency of the proposed model some division schemes are taken into account which improves the performance of the proposed model. The proposed model tackles one of the important restrictions in content based image retrieval, namely, the challenge between the accuracy of retrieval and its time complexity. The experimental results on two databases [19] [24] demonstrate the superiority of the proposed model compared to existing models.},
author = {Giveki, Davar and Soltanshahi, Ali and Shiri, Fatemeh and Tarrah, Hadis},
doi = {http://dx.doi.org/10.4236/jcc.2015.33012},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/New-Content-Based-Image-Retrieval-Model-Based.pdf:pdf},
journal = {Journal of Computer and \ldots},
keywords = {CBIR,Color Moments,HSV Color Space,Image Division,Lab Color Space,RGB Color Space,Wavelet Transform,YCbCr Color Space,YUV Color Space},
number = {March},
pages = {66--73},
title = {{A New Content Based Image Retrieval Model Based on Wavelet Transform}},
url = {http://www.scirp.org/journal/PaperInformation.aspx?paperID=54734},
volume = {3},
year = {2015}
}
@article{Burges1998,
abstract = {The tutorial starts with an overview of the concepts of VC dimension and structural risk minimization. We then describe linear Support Vector Machines (SVMs) for separable and non-separable data, working through a non-trivial example in detail. We describe a mechanical analogy, and discuss when SVM solutions are unique and when they are global. We describe how support vector training can be practically implemented, and discuss in detail the kernel mapping technique which is used to construct SVM solutions which are nonlinear in the data. We show how Support Vector machines can have very large (even infinite) VC dimension by computing the VC dimension for homogeneous polynomial and Gaussian radial basis function kernels. While very high VC dimension would normally bode ill for generalization performance, and while at present there exists no theory which shows that good generalization performance is guaranteed for SVMs, there are several arguments which support the observed high accuracy of SVMs, which we review. Results of some experiments which were inspired by these arguments are also presented. We give numerous examples and proofs of most of the key theorems. There is new material, and I hope that the reader will find that even old material is cast in a fresh light.},
archivePrefix = {arXiv},
arxivId = {1111.6189v1},
author = {Burges, Christopher J C},
doi = {10.1023/A:1009715923555},
editor = {Fayyad, Usama},
eprint = {1111.6189v1},
institution = {Bell Laboratories, Lucent Technologies},
isbn = {0818672404},
issn = {13845810},
journal = {Data Mining and Knowledge Discovery},
keywords = {pattern recognition,statistical learning theory,support vector machines,vc dimension},
number = {2},
pages = {121--167},
pmid = {5207842081938259593},
publisher = {Springer},
series = {NetGames '06},
title = {{A Tutorial on Support Vector Machines for Pattern Recognition}},
url = {http://www.springerlink.com/index/Q87856173126771Q.pdf},
volume = {2},
year = {1998}
}
@inproceedings{macqueen1967,
address = {Berkeley, Calif.},
author = {MacQueen, J},
booktitle = {Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Statistics},
pages = {281--297},
publisher = {University of California Press},
title = {{Some methods for classification and analysis of multivariate observations}},
url = {http://projecteuclid.org/euclid.bsmsp/1200512992},
year = {1967}
}
@article{Wang2015,
abstract = {The Bag-of-visual-words (BOVW) model discards image spatial information, and the computing cost is expensive on spatial pyramid matching(SPM) model. Due to sparse coding approach exhibit super performance in information retrieval, hence, we propose a new sparse coding image retrieval algorithm. Using 2l norm replace 0l norm in SPM vector quantization. The local information was incorporated into sparse term by local adapter. Sparse coding was transformed into least square convex optimization proplem. Each block was encoded by the k nearest neighbor (KNN) approach, and the coding coefficients were integrated by the max pooling function. Each block required different weight according to the image itself information. Euclidean distance and the cosine theorem were combined with the similarity calculation. Our method is evaluated on the two datasets— Caltech-101 and Corel-1000. Comparing with the BOVW and SPM, the results are shown that the new approach greatly improves the image retrieval accuracy.},
author = {Wang, R. X. and Peng, G. H. and Zheng, H. C.},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/007.pdf:pdf},
journal = {International Conference on Artificial Intelligence and Industrial Engineering},
keywords = {bag of visual words,image retrieval,sparse coding,spatial pyramid matching},
number = {Aiie},
pages = {21--24},
title = {{A New Image Retrieval Algorithm Based on Sparse Coding}},
year = {2015}
}
@article{jaakkola1999exploiting,
author = {Jaakkola, Tommi and Haussler, David and Others},
journal = {Advances in neural information processing systems},
pages = {487--493},
publisher = {MIT; 1998},
title = {{Exploiting generative models in discriminative classifiers}},
year = {1999}
}
@article{Rui1999,
author = {Rui, Y and Huang, Ts and Chang, Sf},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/rui99\_cbir\_survey.pdf:pdf},
journal = {Journal of visual communication and image  \ldots},
pages = {39--62},
title = {{Image retrieval: Current techniques, promising directions, and open issues}},
url = {http://www.sciencedirect.com/science/article/pii/S1047320399904133},
volume = {62},
year = {1999}
}
@article{Lowe1999,
abstract = {With the increasing technical sophistication of both information consumers and providers, there is increasing demand for more meaningful experiences of digital information. We present a framework that separates digital object experience, or rendering, from digital object storage and manipulation, so the rendering can be tailored to particular communities of users. Our framework also accommodates extensible digital object behaviors and interoperability. The two key components of our approach are 1) exposing structural metadata associated with digital objects -- metadata about the labeled access points within a digital object and 2) information intermediaries called context brokers that match structural characteristics of digital objects with mechanisms that produce behaviors. These context brokers allow for localized rendering of digital information stored externally.},
archivePrefix = {arXiv},
arxivId = {cs/0112017},
author = {Wendykier, Piotr},
doi = {10.3233/978-1-61499-270-7-57},
eprint = {0112017},
isbn = {9781614992691},
issn = {01675265},
journal = {Mining the Digital Information Networks - Proceedings of the 17th International Conference on Electronic Publishing, ELPUB 2013},
keywords = {Deduplication,Dublin Core,Metadata,OAI-PMH,Open access,Record linkage},
pages = {57--66},
pmid = {15806121},
primaryClass = {cs},
title = {{Deduplication of metadata harvested from open archives initiative repositories}},
volume = {2},
year = {2013}
}
@article{Geurts2006,
abstract = {This paper proposes a newtree-based ensemblemethod for supervised classification and regression problems. It essentially consists of randomizing strongly both attribute and cut-point choice while splitting a tree node. In the extreme case, it builds totally randomized trees whose structures are independent of the output values of the learning sample. The strength of the randomization can be tuned to problem specifics by the appropriate choice of a parameter. We evaluate the robustness of the default choice of this parameter, and we also provide insight on how to adjust it in particular situations. Besides accuracy, the main strength of the resulting algorithm is computational efficiency.Abias/variance analysis of the Extra-Trees algorithm is also provided as well as a geometrical and a kernel characterization of the models induced. Keywords},
author = {Geurts, Pierre and Ernst, Damien and Wehenkel, Louis},
doi = {10.1007/s10994-006-6226-1},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/art\%3A10.1007\%2Fs10994-006-6226-1.pdf:pdf},
isbn = {0885-6125},
issn = {08856125},
journal = {Machine Learning},
keywords = {Bias/variance tradeoff,Cut-point randomization,Decision and regression trees,Ensemble methods,Kernel-based models,Supervised learning},
number = {1},
pages = {3--42},
title = {{Extremely randomized trees}},
volume = {63},
year = {2006}
}
@article{Yihong1994,
abstract = {While general object recognition is difficult, it is relatively easy to capture some inherent image properties, such as color distribution, to narrow down the search range when an attempt to retrieve images from an image database is made. We have built an image database in which images are indexed automatically using a histogram indexing method that we have proposed. With this method, a numerical index key is created for each image histogram using a set of mathematical formulas. By using this approach, we have transformed the difficult problem of image matching into one of image retrieval by index keys, which can be supported by existing database implementation techniques. We have also provided two query methods: image retrieval by user-provided sample images, and image retrieval by combinations of system-provided templates (such as sky, lawn, brick wall, and so on). Our initial experiments on the image database system have shown favorable results},
author = {Yihong, G. and Hongjiang, Z. and Chuan, H.C.},
doi = {10.1109/TENCON.1994.369269},
file = {:home/bluec0re/studium/uni\_hd/semester\_5/thesis/references/00369269.pdf:pdf},
isbn = {0-7803-1862-5},
journal = {Proceedings of TENCON'94 - 1994 IEEE Region 10's 9th Annual International Conference on: 'Frontiers of Computer Technology'},
keywords = {a sunset beach will,a woman strolling on,an image with,be referenced,differently by different users,even,for example,in the database,present,some may use keywords,though the image is,which are not stored},
title = {{An image database system with fast image indexing capability based on color histograms}},
year = {1994}
}
